{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa4c6a6",
   "metadata": {},
   "source": [
    "Check npy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3fcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/mips/X_mips.npy\"\n",
    "data = np.load(file_path)\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2400fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mips_data = np.load(\"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/mips/X_x86.npy\")\n",
    "print(mips_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b8209f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.load(\"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/mips/y.npy\")\n",
    "\n",
    "print(label.shape)\n",
    "print(label[:10])\n",
    "print(label[40000:40010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddb14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/X_arm_merged.npy\"\n",
    "data = np.load(file_path)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924bc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/word2vec/CBOW/sentences_train.pkl\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/dataset/alignment_token/train_arm_token_mixed.pickle\"\n",
    "\n",
    "#check pickle filename and function name\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "#Check index 0-10 and 28748-28758\n",
    "data2 = data[0:10]\n",
    "data3 = data[28748:28758]\n",
    "\n",
    "print(data2)\n",
    "print(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e845a7",
   "metadata": {},
   "source": [
    "Check npy similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d927cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def similarity_score(x_arm, x_mapped):\n",
    "    # Eq.(7): s = 1 / (1 + ||arm - mapped||_2)\n",
    "    dist = torch.norm(x_arm - x_mapped, p=2, dim=1)  # [B]\n",
    "    return 1.0 / (1.0 + dist)\n",
    "\n",
    "\n",
    "arm_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/X_arm.npy\"\n",
    "x86_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/X_x86.npy\"\n",
    "label_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/y.npy\"\n",
    "\n",
    "arm_np = np.load(arm_path)\n",
    "x86_np = np.load(x86_path)\n",
    "label_np = np.load(label_path)\n",
    "\n",
    "#check npy contents\n",
    "\n",
    "print(\"ARM shape:\", arm_np.shape)\n",
    "print(\"x86 shape:\", x86_np.shape)\n",
    "print(\"Label shape:\", label_np.shape)\n",
    "\n",
    "\n",
    "print(\"ARM first 5 vectors:\", arm_np[:5])\n",
    "print(\"x86 first 5 vectors:\", x86_np[:5])\n",
    "print(\"Labels first 10:\", label_np[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 路徑\n",
    "arm_csv  = \"/home/tommy/Projects/pcodeFcg/dataset/alignment/arm_32_alignment.csv\"\n",
    "mips_csv = \"/home/tommy/Projects/pcodeFcg/dataset/alignment/mips_32_alignment.csv\"\n",
    "w2v_path  = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/word2vec/CBOW/word2vec.model\"\n",
    "\n",
    "# 讀檔\n",
    "df_arm  = pd.read_csv(arm_csv)   # 欄位：file_name,function_name,pcode,label\n",
    "df_mips = pd.read_csv(mips_csv)\n",
    "w2v     = Word2Vec.load(w2v_path)\n",
    "\n",
    "# 前 5 筆同列比對（ARM vs MIPS row-wise）\n",
    "print(\"=== 同一列前 5 筆 Cosine Similarity ===\")\n",
    "for i in range(5):\n",
    "    toks_arm  = str(df_arm.loc[i, \"pcode\"]).split()\n",
    "    toks_mips = str(df_mips.loc[i, \"pcode\"]).split()\n",
    "    vec_arm   = np.mean([w2v.wv[t] for t in toks_arm  if t in w2v.wv] or [np.zeros(w2v.vector_size)], axis=0)\n",
    "    vec_mips  = np.mean([w2v.wv[t] for t in toks_mips if t in w2v.wv] or [np.zeros(w2v.vector_size)], axis=0)\n",
    "    sim        = cosine_similarity(vec_arm.reshape(1,-1), vec_mips.reshape(1,-1))[0,0]\n",
    "    print(f\"Row {i}: {sim:.4f}\")\n",
    "\n",
    "# 隨機 5 筆不同行比對（ARM row i vs MIPS row j, i != j）\n",
    "print(\"\\n=== 隨機 5 筆不同行 Cosine Similarity ===\")\n",
    "n = len(df_arm)\n",
    "pairs = set()\n",
    "while len(pairs) < 5:\n",
    "    i = random.randrange(n)\n",
    "    j = random.randrange(n)\n",
    "    if i != j:\n",
    "        pairs.add((i, j))\n",
    "\n",
    "for i, j in pairs:\n",
    "    toks_arm  = str(df_arm.loc[i, \"pcode\"]).split()\n",
    "    toks_mips = str(df_mips.loc[j, \"pcode\"]).split()\n",
    "    vec_arm   = np.mean([w2v.wv[t] for t in toks_arm  if t in w2v.wv] or [np.zeros(w2v.vector_size)], axis=0)\n",
    "    vec_mips  = np.mean([w2v.wv[t] for t in toks_mips if t in w2v.wv] or [np.zeros(w2v.vector_size)], axis=0)\n",
    "    sim        = cosine_similarity(vec_arm.reshape(1,-1), vec_mips.reshape(1,-1))[0,0]\n",
    "    print(f\"ARM row {i} vs MIPS row {j}: {sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673c44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "# 1. 載入你訓練好的 Adapter\n",
    "from model import Adapter  \n",
    "ckpt = torch.load(\n",
    "    '/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/simsiam_adapter.pth',\n",
    "    map_location='cpu'\n",
    ")\n",
    "state_dict = ckpt.get('state_dict', ckpt)\n",
    "adapter_state = {\n",
    "    k[len('backbone.'):]: v\n",
    "    for k, v in state_dict.items()\n",
    "    if k.startswith('backbone.adapter.')\n",
    "}\n",
    "adapter = Adapter(dim=256, num_blocks=2)\n",
    "adapter.load_state_dict(adapter_state, strict=False)\n",
    "adapter.eval()\n",
    "\n",
    "# 2. 指定單一對應檔案路徑\n",
    "path_src = '/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/train/0b/0b61ed19ec8d9450268020524aae18ff68071164042097c346afe9085b72135d.gpickle'\n",
    "path_tgt = '/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/test/0a/0a3eab21fff9e3edbb22861e6d1c461dee66e36cc2f0010602eaff0496ed8271.gpickle'\n",
    "\n",
    "# 3. 讀入圖\n",
    "with open(path_src, 'rb') as f:\n",
    "    G_src = pickle.load(f)\n",
    "    print(G_src)\n",
    "    for node in G_src.nodes():\n",
    "        print(G_src.nodes[node]['vector'])\n",
    "with open(path_tgt, 'rb') as f:\n",
    "    G_tgt = pickle.load(f)\n",
    "    print(G_tgt)\n",
    "\n",
    "# 4. 比較每個 node\n",
    "print(f'Comparing {os.path.basename(path_src)} → {os.path.basename(path_tgt)}\\n')\n",
    "print('Node\\tOrigDist\\tMappedDist')\n",
    "for node in G_src.nodes():\n",
    "    if node not in G_tgt:\n",
    "        continue\n",
    "    x_src = torch.tensor(G_src.nodes[node]['vector'], dtype=torch.float32)\n",
    "    x_tgt = torch.tensor(G_tgt.nodes[node]['vector'], dtype=torch.float32)\n",
    "    # 原始距離\n",
    "    d_orig = torch.dist(x_src, x_tgt).item()\n",
    "    # 經 adapter 映射後距離\n",
    "    x_mapped = adapter(x_src.unsqueeze(0)).squeeze(0)\n",
    "    d_mapped = torch.dist(x_mapped, x_tgt).item()\n",
    "    print(f'{node}\\t{d_orig:.4f}\\t{d_mapped:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e14073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/dataset/alignment/train.pickle\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(f\"Data loaded from {file_path}, length: {len(data)}\")\n",
    "print(data[:1])  # Print first 5 items to verify structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d666e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_no_mix/test/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "\n",
    "with open(file_path, \"rb\") as fp:\n",
    "    G = pickle.load(fp)\n",
    "    for addr, data in G.nodes(data=True):\n",
    "        print(f\"Node: {addr}, Data: {data}\")\n",
    "        \n",
    "    print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "    print(f\"Shape of node vectors:{len(data['vector']) if 'vector' in data else 'N/A'}\")\n",
    "    print(f\"Sample node data: {list(G.nodes(data=True))[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/word2vec/CBOW_no_mix/sentences_train.pkl\"\n",
    "with open(file_path, 'rb') as f:\n",
    "    sentences = pickle.load(f)\n",
    "print(f\"Number of sentences: {len(sentences)}\")\n",
    "print(f\"First 5 sentences: {sentences[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64afaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/dataset/alignment_token/train_arm_token.pickle\"\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(type(data))\n",
    "\n",
    "for i, item in enumerate(data):\n",
    "    print(f\"Item {i}: {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f3759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_path=\"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "\n",
    "with open(file_path, 'rb') as fp:\n",
    "    G = pickle.load(fp)\n",
    "    print(G)\n",
    "first_node = list(G.nodes(data=True))[0]\n",
    "# print(first_node)\n",
    "\n",
    "vector = first_node[1]['vector']\n",
    "print(f\"Vector length: {len(vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9080665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Adapter\n",
    "import torch\n",
    "model_path = '/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/simsiam_adapter.pth'\n",
    "ckpt = torch.load(model_path, map_location='cpu')\n",
    "state_dict = ckpt.get('state_dict', ckpt)\n",
    "adapter_state = {\n",
    "    k[len('backbone.'):]: v\n",
    "    for k, v in state_dict.items()\n",
    "    if k.startswith('backbone.adapter.')\n",
    "}\n",
    "\n",
    "print(list(adapter_state.keys()))\n",
    "\n",
    "\n",
    "adapter = Adapter(dim=256, num_blocks=2)\n",
    "missing, unexpected = adapter.load_state_dict(adapter_state, strict=False)\n",
    "print('Missing keys:', missing)\n",
    "print('Unexpected keys:', unexpected)\n",
    "adapter.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "def load_vectors(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        G = pickle.load(f) \n",
    "    return [torch.tensor(d['vector'], dtype=torch.float32) for _, d in G.nodes(data=True)]\n",
    "\n",
    "def avg_cosine_similarity(vecs1, vecs2):\n",
    "    mean1 = torch.stack(vecs1).mean(dim=0)\n",
    "    mean2 = torch.stack(vecs2).mean(dim=0)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(mean1.unsqueeze(0), mean2.unsqueeze(0))\n",
    "    return cos_sim.item()\n",
    "\n",
    "# file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train/00/0036f76612926fba2f71297dd4d13f326173f38662e8f639a5f1db0195cc56ee.gpickle\"\n",
    "# arm_file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train_transfer/00/0036f76612926fba2f71297dd4d13f326173f38662e8f639a5f1db0195cc56ee.gpickle\"\n",
    "arm_file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_transfer/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "\n",
    "vecs1 = load_vectors(file_path)\n",
    "vecs2 = load_vectors(arm_file_path)\n",
    "\n",
    "score = avg_cosine_similarity(vecs1, vecs2)\n",
    "print(f\"Average cosine similarity: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d1708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "def load_vectors(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    return [torch.tensor(d['vector'], dtype=torch.float32) for _, d in G.nodes(data=True)]\n",
    "\n",
    "def avg_file_vector(path):\n",
    "    vecs = load_vectors(path)\n",
    "    return torch.stack(vecs).mean(dim=0)\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        v1.unsqueeze(0), v2.unsqueeze(0)\n",
    "    ).item()\n",
    "\n",
    "# paths\n",
    "train_csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\"\n",
    "test_csv_path  = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\"\n",
    "\n",
    "train_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train\"\n",
    "test_dir  = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm\"\n",
    "train_transfer_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train_transfer_merged\"\n",
    "test_transfer_dir  = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_transfer_merged\"\n",
    "\n",
    "# load CSVs\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_df  = pd.read_csv(test_csv_path)\n",
    "\n",
    "# group by labels\n",
    "labels = [\"benign\", \"mirai\", \"gafgyt\", \"tsunami\"]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for label in labels:\n",
    "    # 找到該 label 的檔案\n",
    "    train_files = train_df[train_df[\"label\"] == label][\"file_name\"].tolist()\n",
    "    test_files  = test_df[test_df[\"label\"] == label][\"file_name\"].tolist()\n",
    "\n",
    "    if not train_files or not test_files:\n",
    "        continue\n",
    "\n",
    "    # 隨機取最多 100 個 (不足就全取)\n",
    "    train_files = random.sample(train_files, min(100, len(train_files)))\n",
    "    test_files  = random.sample(test_files, min(100, len(test_files)))\n",
    "\n",
    "    sims_before, sims_after = [], []\n",
    "\n",
    "    for tf in train_files:\n",
    "        train_path = os.path.join(train_dir, tf + \".gpickle\")\n",
    "        train_path_t = os.path.join(train_transfer_dir, tf + \".gpickle\")\n",
    "        if not os.path.exists(train_path) or not os.path.exists(train_path_t):\n",
    "            continue\n",
    "        v_train = avg_file_vector(train_path)\n",
    "        v_train_t = avg_file_vector(train_path_t)\n",
    "\n",
    "        for tef in test_files:\n",
    "            test_path = os.path.join(test_dir, tef + \".gpickle\")\n",
    "            test_path_t = os.path.join(test_transfer_dir, tef + \".gpickle\")\n",
    "            if not os.path.exists(test_path) or not os.path.exists(test_path_t):\n",
    "                continue\n",
    "            v_test = avg_file_vector(test_path)\n",
    "            v_test_t = avg_file_vector(test_path_t)\n",
    "\n",
    "            sims_before.append(cosine_similarity(v_train, v_test))\n",
    "            sims_after.append(cosine_similarity(v_train_t, v_test_t))\n",
    "\n",
    "    if sims_before and sims_after:\n",
    "        results[label] = {\n",
    "            \"before\": sum(sims_before) / len(sims_before),\n",
    "            \"after\": sum(sims_after) / len(sims_after),\n",
    "        }\n",
    "\n",
    "# 印出結果\n",
    "for label, vals in results.items():\n",
    "    print(f\"Label: {label}\")\n",
    "    print(f\"  Avg similarity before transfer: {vals['before']:.4f}\")\n",
    "    print(f\"  Avg similarity after  transfer: {vals['after']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639715ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "def load_vectors(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    return [torch.tensor(d['vector'], dtype=torch.float32) for _, d in G.nodes(data=True)]\n",
    "\n",
    "def avg_cosine_similarity(vecs1, vecs2):\n",
    "    mean1 = torch.stack(vecs1).mean(dim=0)\n",
    "    mean2 = torch.stack(vecs2).mean(dim=0)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(mean1.unsqueeze(0), mean2.unsqueeze(0))\n",
    "    return cos_sim.item()\n",
    "\n",
    "# 原始 & transfer 資料夾\n",
    "train_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train\"\n",
    "test_dir  = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test\"\n",
    "train_transfer_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train_transfer_O0\"\n",
    "test_transfer_dir  = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_transfer_O0\"\n",
    "\n",
    "# 收集檔案\n",
    "train_files, test_files = [], []\n",
    "for root, _, files in os.walk(train_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".gpickle\"):\n",
    "            train_files.append(os.path.join(root, f))\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for f in files:\n",
    "        if f.endswith(\".gpickle\"):\n",
    "            test_files.append(os.path.join(root, f))\n",
    "\n",
    "# 隨機抽 50 對\n",
    "pairs = random.sample(list(zip(train_files, test_files)), 1000)\n",
    "\n",
    "sims_before, sims_after = [], []\n",
    "\n",
    "for train_f, test_f in pairs:\n",
    "    rel_train = os.path.relpath(train_f, train_dir)\n",
    "    rel_test  = os.path.relpath(test_f, test_dir)\n",
    "    train_f_transfer = os.path.join(train_transfer_dir, rel_train)\n",
    "    test_f_transfer  = os.path.join(test_transfer_dir, rel_test)\n",
    "\n",
    "    vecs1 = load_vectors(train_f)\n",
    "    vecs2 = load_vectors(test_f)\n",
    "    sims_before.append(avg_cosine_similarity(vecs1, vecs2))\n",
    "\n",
    "    vecs1_t = load_vectors(train_f_transfer)\n",
    "    vecs2_t = load_vectors(test_f_transfer)\n",
    "    sims_after.append(avg_cosine_similarity(vecs1_t, vecs2_t))\n",
    "\n",
    "print(f\"Average similarity before transfer: {sum(sims_before)/len(sims_before):.4f}\")\n",
    "print(f\"Average similarity after  transfer: {sum(sims_after)/len(sims_after):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59798a2f",
   "metadata": {},
   "source": [
    "Check pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468533e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"/home/tommy/Projects/pcodeFcg/dataset/alignment_token/train_arm_token_Os.pickle\", 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "print(len(data))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43afb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 檔案路徑\n",
    "file_path_arm = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/X_arm_merged.npy\"\n",
    "file_path_x86 = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/X_x86_merged.npy\"\n",
    "file_path_y   = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/y_merged.npy\"\n",
    "\n",
    "# 讀取 numpy 向量\n",
    "X_arm = np.load(file_path_arm)\n",
    "X_x86 = np.load(file_path_x86)\n",
    "y     = np.load(file_path_y)\n",
    "\n",
    "# 轉成 torch tensor\n",
    "X_arm_t = torch.tensor(X_arm, dtype=torch.float32)\n",
    "X_x86_t = torch.tensor(X_x86, dtype=torch.float32)\n",
    "\n",
    "# 計算平均 cosine similarity\n",
    "def avg_cosine_similarity(vecs1, vecs2):\n",
    "    mean1 = vecs1.mean(dim=0, keepdim=True)\n",
    "    mean2 = vecs2.mean(dim=0, keepdim=True)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(mean1, mean2)\n",
    "    return cos_sim.item()\n",
    "\n",
    "cos_sim = avg_cosine_similarity(X_arm_t, X_x86_t)\n",
    "print(f\"ARM vs x86 平均 cosine similarity = {cos_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c40e93",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fde267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from model import Adapter\n",
    "import numpy as np\n",
    "\n",
    "alignment_model = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/simsiam_adapter_merged.pth\"\n",
    "file_path_arm = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/X_arm_merged.npy\"\n",
    "file_path_x86 = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/resnet/arm_cbow_v2/X_x86_merged.npy\"\n",
    "\n",
    "X_arm = np.load(file_path_arm)\n",
    "X_x86 = np.load(file_path_x86)\n",
    "X_arm_t = torch.tensor(X_arm, dtype=torch.float32)\n",
    "X_x86_t = torch.tensor(X_x86, dtype=torch.float32)\n",
    "\n",
    "ckpt = torch.load(alignment_model, map_location='cpu')\n",
    "state_dict = ckpt.get('state_dict', ckpt)\n",
    "adapter_state = {\n",
    "    k[len('backbone.'):]: v\n",
    "    for k, v in state_dict.items()\n",
    "    if k.startswith('backbone.adapter.')\n",
    "}\n",
    "adapter = Adapter(dim=256, num_blocks=2)\n",
    "adapter.load_state_dict(adapter_state, strict=False)\n",
    "adapter.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    z_arm = adapter(X_arm_t) \n",
    "    z_x86 = adapter(X_x86_t) \n",
    "\n",
    "# 計算平均 cosine similarity\n",
    "def avg_cosine_similarity(vecs1, vecs2):\n",
    "    mean1 = vecs1.mean(dim=0, keepdim=True)\n",
    "    mean2 = vecs2.mean(dim=0, keepdim=True)\n",
    "    cos_sim = torch.nn.functional.cosine_similarity(mean1, mean2)\n",
    "    return cos_sim.item()\n",
    "\n",
    "cos_before = avg_cosine_similarity(X_arm_t, X_x86_t)\n",
    "cos_after  = avg_cosine_similarity(z_arm, z_x86)\n",
    "\n",
    "print(f\"對齊前 ARM vs x86 平均 cosine similarity = {cos_before:.4f}\")\n",
    "print(f\"對齊後 ARM vs x86 平均 cosine similarity = {cos_after:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e623a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_4_class/train\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\"\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train_transfer\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transfer\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 兩組資料\n",
    "datasets = [\n",
    "    {\n",
    "        \"csv\": \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\",\n",
    "        \"gpickle\": \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train_transferred_Os\"\n",
    "    },\n",
    "    {\n",
    "        \"csv\": \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\",\n",
    "        \"gpickle\": \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transferred_Os\"\n",
    "    }\n",
    "]\n",
    "\n",
    "file_vectors, labels, cpus = [], [], []\n",
    "\n",
    "for dataset in datasets:\n",
    "    df = pd.read_csv(dataset[\"csv\"])  # file_name, CPU, label\n",
    "    gpickle_dir = dataset[\"gpickle\"]\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        file_name = row[\"file_name\"]\n",
    "        cpu = row[\"CPU\"]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        prefix = file_name[:2]\n",
    "        gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "\n",
    "        if not os.path.exists(gpickle_path):\n",
    "            print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "            continue\n",
    "\n",
    "        # G = nx.read_gpickle(gpickle_path)\n",
    "        with open(gpickle_path, \"rb\") as f:\n",
    "            G = pickle.load(f)\n",
    "\n",
    "        node_vecs = [\n",
    "            torch.tensor(d[\"vector\"], dtype=torch.float32)\n",
    "            for _, d in G.nodes(data=True) if \"vector\" in d\n",
    "        ]\n",
    "\n",
    "        if not node_vecs:\n",
    "            continue\n",
    "\n",
    "        mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "        file_vectors.append(mean_vec)\n",
    "        labels.append(label)\n",
    "        cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 定義 CPU 對應顏色\n",
    "cpu_colors = {\n",
    "    \"arm\": \"red\",\n",
    "    \"mips\": \"blue\",\n",
    "    \"x86\": \"green\"\n",
    "}\n",
    "\n",
    "# 定義 label 對應 marker\n",
    "label_markers = {\n",
    "    \"benign\": \"o\",\n",
    "    \"gafgyt\": \"s\",\n",
    "    \"mirai\": \"D\",\n",
    "    \"tsunami\": \"^\"\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for i, (x, y) in enumerate(tsne_result):\n",
    "    cpu = cpus[i]\n",
    "    label = labels[i]\n",
    "    plt.scatter(\n",
    "        x, y,\n",
    "        c=cpu_colors.get(cpu, \"black\"),\n",
    "        marker=label_markers.get(label, \"o\"),\n",
    "        alpha=0.7,\n",
    "        edgecolors=\"k\",\n",
    "        linewidths=0.3\n",
    "    )\n",
    "\n",
    "# 建立 legend\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "legend_elements = []\n",
    "\n",
    "# CPU legend\n",
    "for cpu, color in cpu_colors.items():\n",
    "    legend_elements.append(Line2D([0], [0], marker=\"o\", color=\"w\", label=f\"CPU={cpu}\",\n",
    "                                  markerfacecolor=color, markersize=10))\n",
    "\n",
    "# Label legend\n",
    "for lbl, marker in label_markers.items():\n",
    "    legend_elements.append(Line2D([0], [0], marker=marker, color=\"k\", label=f\"Label={lbl}\",\n",
    "                                  markerfacecolor=\"w\", markersize=10))\n",
    "\n",
    "plt.legend(handles=legend_elements, loc=\"best\")\n",
    "plt.title(\"t-SNE of gpickle file representations\\nColor=CPU, Shape=Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/train.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/train\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2183a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\"\n",
    "gpickle_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transfer\"\n",
    "\n",
    "df = pd.read_csv(csv_path)  # file_name, CPU, label\n",
    "\n",
    "file_vectors = []\n",
    "labels = []\n",
    "cpus = []\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    file_name = row[\"file_name\"]\n",
    "    cpu = row[\"CPU\"]\n",
    "    label = row[\"label\"]\n",
    "    prefix = file_name[:2]\n",
    "    gpickle_path = os.path.join(gpickle_dir, prefix, file_name + \".gpickle\")\n",
    "    if not os.path.exists(gpickle_path):\n",
    "        print(f\"[WARN] gpickle not found: {gpickle_path}\")\n",
    "        continue\n",
    "    with open(gpickle_path, \"rb\") as f:\n",
    "        G = pickle.load(f)\n",
    "    node_vecs = []\n",
    "    for _, d in G.nodes(data=True):\n",
    "        if \"vector\" in d:\n",
    "            node_vecs.append(torch.tensor(d[\"vector\"], dtype=torch.float32))\n",
    "\n",
    "    if not node_vecs:\n",
    "        continue\n",
    "\n",
    "    mean_vec = torch.stack(node_vecs).mean(dim=0).numpy()\n",
    "    file_vectors.append(mean_vec)\n",
    "    labels.append(label)\n",
    "    cpus.append(cpu)\n",
    "\n",
    "file_vectors = np.array(file_vectors)\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_ids = le.fit_transform(labels) \n",
    "\n",
    "# t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "tsne_result = tsne.fit_transform(file_vectors)\n",
    "\n",
    "# 畫圖\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    tsne_result[:, 0], tsne_result[:, 1],\n",
    "    c=label_ids, cmap=\"tab10\", alpha=0.7\n",
    ")\n",
    "handles, _ = scatter.legend_elements()\n",
    "plt.legend(handles, le.classes_, title=\"Label\")\n",
    "\n",
    "plt.title(\"t-SNE of gpickle file representations\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb10c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"/home/tommy/Projects/pcodeFcg/dataset/alignment_vector/train_arm_vector.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(len(data))\n",
    "# check data structure\n",
    "\n",
    "print(type(data))\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e08711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "file_path_2 = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm/13/13abb7d77381e30d323c3af1fbc7e2c5c7c91c5204fa18589139020670c4ecdf.gpickle\"\n",
    "\n",
    "file_path_transfer = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transferred_Os/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "file_path_2_transfer = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transferred_Os/13/13abb7d77381e30d323c3af1fbc7e2c5c7c91c5204fa18589139020670c4ecdf.gpickle\"\n",
    "\n",
    "with open(file_path, \"rb\") as fp:\n",
    "    G = pickle.load(fp)\n",
    "    print(G)\n",
    "    first_node = list(G.nodes(data=True))[0]\n",
    "    # print(first_node)\n",
    "    vector = first_node[1]['vector']\n",
    "    print(f\"Vector length: {len(vector)}\")\n",
    "\n",
    "with open(file_path_2, \"rb\") as fp:\n",
    "    G = pickle.load(fp)\n",
    "    print(G)\n",
    "    first_node = list(G.nodes(data=True))[0]\n",
    "    # print(first_node)\n",
    "    vector = first_node[1]['vector']\n",
    "    print(f\"Vector length: {len(vector)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17753099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import networkx as nx\n",
    "\n",
    "def load_avg_vector(file_path):\n",
    "    with open(file_path, \"rb\") as fp:\n",
    "        G = pickle.load(fp)\n",
    "    # 把所有 node 的 vector 取平均\n",
    "    vectors = [torch.tensor(d['vector'], dtype=torch.float32) for _, d in G.nodes(data=True)]\n",
    "    if len(vectors) == 0:\n",
    "        return None\n",
    "    return torch.stack(vectors).mean(dim=0)\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return torch.nn.functional.cosine_similarity(v1.unsqueeze(0), v2.unsqueeze(0)).item()\n",
    "\n",
    "file_path = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "file_path_2 = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm/13/13abb7d77381e30d323c3af1fbc7e2c5c7c91c5204fa18589139020670c4ecdf.gpickle\"\n",
    "\n",
    "file_path_transfer = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transferred_Os/00/00a6f39a8f7b14f223fa51a9a23aa110112a524799e910e321b162847a875593.gpickle\"\n",
    "file_path_2_transfer = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2/test_arm_transferred_Os/13/13abb7d77381e30d323c3af1fbc7e2c5c7c91c5204fa18589139020670c4ecdf.gpickle\"\n",
    "\n",
    "# 原始\n",
    "vec1 = load_avg_vector(file_path)\n",
    "vec2 = load_avg_vector(file_path_2)\n",
    "orig_sim = cosine_similarity(vec1, vec2)\n",
    "\n",
    "# transferred 後\n",
    "vec1_t = load_avg_vector(file_path_transfer)\n",
    "vec2_t = load_avg_vector(file_path_2_transfer)\n",
    "transfer_sim = cosine_similarity(vec1_t, vec2_t)\n",
    "\n",
    "print(f\"Original similarity:   {orig_sim:.4f}\")\n",
    "print(f\"Transferred similarity: {transfer_sim:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a4294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 450/450 [00:01<00:00, 232.88it/s]\n",
      "Computing similarities: 100%|██████████| 100/100 [00:00<00:00, 5382.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "平均 Original similarity:   0.9309\n",
      "平均 Transferred similarity: 0.4702\n",
      "有效檔案數: 441 / 450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def load_avg_vector(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    try:\n",
    "        with open(file_path, \"rb\") as fp:\n",
    "            G = pickle.load(fp)\n",
    "        vectors = [torch.tensor(d['vector'], dtype=torch.float32) for _, d in G.nodes(data=True)]\n",
    "        if not vectors:\n",
    "            return None\n",
    "        return torch.stack(vectors).mean(dim=0)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return torch.nn.functional.cosine_similarity(\n",
    "        v1.unsqueeze(0), v2.unsqueeze(0)\n",
    "    ).item()\n",
    "\n",
    "def process_pair(row):\n",
    "    file_name = row[\"file_name\"]\n",
    "    base_dir = \"/home/tommy/Projects/pcodeFcg/vector/contrastive/GNN/arm_cbow_v2\"\n",
    "\n",
    "    orig_path = os.path.join(base_dir, \"test_arm\", file_name[:2], file_name + \".gpickle\")\n",
    "    trans_path = os.path.join(base_dir, \"test_transferred_align_labse\", file_name[:2], file_name + \".gpickle\")\n",
    "\n",
    "    v_orig = load_avg_vector(orig_path)\n",
    "    v_trans = load_avg_vector(trans_path)\n",
    "\n",
    "    if v_orig is None or v_trans is None:\n",
    "        return None\n",
    "\n",
    "    return {\"file\": file_name, \"orig_vector\": v_orig, \"trans_vector\": v_trans}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_path = \"/home/tommy/Projects/pcodeFcg/dataset/csv/temp/test_arm.csv\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[df[\"label\"] == \"benign\"]  # 只跑 benign\n",
    "\n",
    "    rows = df.to_dict(orient=\"records\")\n",
    "\n",
    "    with Pool(processes=cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_pair, rows), total=len(rows)))\n",
    "\n",
    "    results = [r for r in results if r]  # 過濾掉缺失或錯誤\n",
    "\n",
    "    # 隨機選 100 對 pair 減少 O(n^2) 計算量\n",
    "    import random\n",
    "    sims_orig, sims_trans = [], []\n",
    "    sample_pairs = random.sample(\n",
    "        [(i, j) for i in range(len(results)) for j in range(i + 1, len(results))],\n",
    "        min(100, len(results) * (len(results) - 1) // 2)  # 最多 100 對\n",
    "    )\n",
    "\n",
    "    for i, j in tqdm(sample_pairs, desc=\"Computing similarities\"):\n",
    "        sims_orig.append(cosine_similarity(results[i][\"orig_vector\"], results[j][\"orig_vector\"]))\n",
    "        sims_trans.append(cosine_similarity(results[i][\"trans_vector\"], results[j][\"trans_vector\"]))\n",
    "\n",
    "    print(f\"\\n平均 Original similarity:   {sum(sims_orig) / len(sims_orig):.4f}\")\n",
    "    print(f\"平均 Transferred similarity: {sum(sims_trans) / len(sims_trans):.4f}\")\n",
    "    print(f\"有效檔案數: {len(results)} / {len(rows)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cross-architecture",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
